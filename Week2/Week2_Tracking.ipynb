{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlgpXkPsbklh"
   },
   "source": [
    "# **SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odns-Tw_iUZh",
    "outputId": "c17e67c7-8395-4090-c6f4-f40ca8d68f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filterpy in /usr/local/lib/python3.11/dist-packages (1.4.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.13.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from filterpy) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7EwlJHnW3LC",
    "outputId": "43d408a1-889a-4b22-e80d-789c23bf8243"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import rc as rc\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set the animation embed limit to 50 MB\n",
    "mpl.rcParams['animation.embed_limit'] = 1000\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twq7M9Eaew5I"
   },
   "source": [
    "# **VIDEO PLAYER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s98CbXPxfNZq"
   },
   "outputs": [],
   "source": [
    "def draw_text(img, text,\n",
    "          pos=(0, 0),\n",
    "          font=cv2.FONT_HERSHEY_PLAIN,\n",
    "          font_scale=3.0,\n",
    "          font_thickness=2,\n",
    "          text_color=(0, 255, 0),\n",
    "          text_color_bg=(0, 0, 0)\n",
    "          ):\n",
    "\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, round(y + text_h + font_scale - 1)), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    return text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYQzjrwwey4r",
    "outputId": "734574cc-b15e-45c4-b87e-fdda6d95089a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "class VideoPlayer:\n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.figsize = (5, round(5 / self.width * self.height))\n",
    "\n",
    "        print(self.figsize)\n",
    "\n",
    "        # Close immediately if you only need the metadata\n",
    "        self.cap.release()\n",
    "\n",
    "    def get_frames(self, start_frame, end_frame):\n",
    "        \"\"\"\n",
    "        Returns all frames in RGB from start_frame (inclusive) to end_frame (exclusive).\n",
    "        \"\"\"\n",
    "        if start_frame >= self.frame_count:\n",
    "            return np.array([])\n",
    "\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        frames = []\n",
    "        for frame_idx in range(start_frame, end_frame):\n",
    "            if frame_idx >= self.frame_count:\n",
    "                break\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "        cap.release()\n",
    "        return np.array(frames)\n",
    "\n",
    "    def plot(\n",
    "        self,\n",
    "        start_frame=0,\n",
    "        end_frame=100,\n",
    "        bounding_boxes_gt=None,\n",
    "        bounding_boxes_pred=None,\n",
    "        gt_color=(0, 255, 0),\n",
    "        pred_color=(255, 0, 0),\n",
    "        bbox_thickness=5,\n",
    "        save_file=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Displays an animation of the video frames within [start_frame, end_frame).\n",
    "        Optionally draws bounding boxes for ground-truth and predicted data,\n",
    "        with track IDs rendered in a small filled square of the same color:\n",
    "        - GT ID near top-left corner\n",
    "        - Pred ID near top-right corner\n",
    "        \"\"\"\n",
    "        frames = self.get_frames(start_frame, end_frame)\n",
    "        if len(frames) == 0:\n",
    "            print(\"No frames to display for the specified frame range.\")\n",
    "            return\n",
    "\n",
    "        processed_frames = []\n",
    "        label_box_size = 30  # Size (width=height) of the track ID \"label box\"\n",
    "\n",
    "        for i, frame in enumerate(frames):\n",
    "            # Convert to uint8 for drawing bounding boxes in OpenCV\n",
    "            out_frame_uint8 = frame.astype(np.uint8)\n",
    "\n",
    "            # Draw ground-truth bounding boxes\n",
    "            if bounding_boxes_gt is not None:\n",
    "                for gt_box in bounding_boxes_gt[i + start_frame]:\n",
    "                    x, y, w, h = gt_box[\"bbox\"]\n",
    "                    # Draw the bounding box\n",
    "                    cv2.rectangle(\n",
    "                        out_frame_uint8,\n",
    "                        (int(x), int(y)), (int(x + w), int(y + h)),\n",
    "                        color=gt_color,\n",
    "                        thickness=bbox_thickness\n",
    "                    )\n",
    "                    # Draw the track_id box (if present)\n",
    "                    if \"track_id\" in gt_box:\n",
    "                        tid = str(gt_box[\"track_id\"])\n",
    "                        # Draw a small filled square in the top-left corner of the box\n",
    "                        lx, ly = int(x + 0.25*w), int(y + h + 5)\n",
    "                        # Put the text in white\n",
    "                        draw_text(\n",
    "                            out_frame_uint8,\n",
    "                            tid,\n",
    "                            pos=(lx, ly),  # approximate vertical center\n",
    "                            font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            font_scale=1.25,  # font scale\n",
    "                            text_color=(0, 0, 0),  # white text\n",
    "                            font_thickness=3,  # text thickness\n",
    "                            text_color_bg=gt_color\n",
    "                        )\n",
    "\n",
    "            # Draw predicted bounding boxes\n",
    "            if bounding_boxes_pred is not None:\n",
    "                for pred_box in bounding_boxes_pred[i + start_frame]:\n",
    "                    x, y, w, h = pred_box[\"bbox\"]\n",
    "                    cv2.rectangle(\n",
    "                        out_frame_uint8,\n",
    "                        (int(x), int(y)), (int(x + w), int(y + h)),\n",
    "                        color=pred_color,\n",
    "                        thickness=bbox_thickness\n",
    "                    )\n",
    "                    # Draw the track_id box (if present)\n",
    "                    if \"track_id\" in pred_box:\n",
    "                        tid = str(pred_box[\"track_id\"])\n",
    "                        # Draw a small filled square in the top-right corner of the box\n",
    "                        lx, ly = int(x + 0.75*w), int(y + h + 5)\n",
    "                        draw_text(\n",
    "                            out_frame_uint8,\n",
    "                            tid,\n",
    "                            pos=(lx, ly),  # approximate vertical center\n",
    "                            font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            font_scale=1.25,  # font scale\n",
    "                            text_color=(0, 0, 0),  # white text\n",
    "                            font_thickness=3,  # text thickness\n",
    "                            text_color_bg=pred_color\n",
    "                        )\n",
    "\n",
    "            processed_frames.append(out_frame_uint8)\n",
    "\n",
    "        processed_frames = np.array(processed_frames)\n",
    "\n",
    "        # Create the Matplotlib animation\n",
    "        fig, ax = plt.subplots(figsize=self.figsize)\n",
    "        img_display = ax.imshow(processed_frames[0])\n",
    "        ax.set_title(f\"Frame: {start_frame + 1}/{self.frame_count}\")\n",
    "        ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        def update(frame_idx):\n",
    "            img_display.set_data(processed_frames[frame_idx])\n",
    "            ax.set_title(f\"Frame: {start_frame + frame_idx + 1}/{self.frame_count}\")\n",
    "            return (img_display,)\n",
    "\n",
    "        anim = FuncAnimation(\n",
    "            fig,\n",
    "            update,\n",
    "            frames=len(processed_frames),\n",
    "            interval=1000 / self.fps if self.fps else 40,\n",
    "            blit=True\n",
    "        )\n",
    "\n",
    "        if save_file is not None:\n",
    "            from matplotlib.animation import FFMpegWriter, PillowWriter\n",
    "            ext = save_file.lower().rsplit('.', 1)[-1]\n",
    "            fps_for_save = int(self.fps) if self.fps else 30\n",
    "\n",
    "            if ext == 'gif':\n",
    "                writer = PillowWriter(fps=fps_for_save)\n",
    "            else:\n",
    "                writer = FFMpegWriter(fps=fps_for_save, metadata={'title': 'Video Output'})\n",
    "\n",
    "            anim.save(save_file, writer=writer)\n",
    "            print(f\"Animation saved to {save_file}\")\n",
    "        else:\n",
    "            IPython.display.display(anim)\n",
    "            plt.close(fig)\n",
    "\n",
    "video_path = '../train/S03/c010/vdo.avi'\n",
    "video_player = VideoPlayer(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64V6eKeHbm1M"
   },
   "source": [
    "# **I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blQ_cWRxgmt0"
   },
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xe4_V7VJgo8L"
   },
   "outputs": [],
   "source": [
    "def parse_cvat_annotations(xml_path):\n",
    "    \"\"\"\n",
    "    Reads a CVAT annotation XML file and returns ground truth data\n",
    "    in a dict of the form:\n",
    "        {\n",
    "            frame_idx: [\n",
    "                {\n",
    "                    \"bbox\": [x, y, w, h],\n",
    "                    \"category_id\": <int>,\n",
    "                    \"track_id\": <str>\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            ...\n",
    "        }\n",
    "\n",
    "    Assumptions/notes:\n",
    "      - Only 'outside=\"0\"' (visible) objects will be returned.\n",
    "      - Only non-parked objects are returned (based on <attribute name=\"parked\">).\n",
    "      - The default category_id is given by label_to_id below; unrecognized labels\n",
    "        will get new IDs assigned automatically.\n",
    "      - Frame indices are taken from the 'box' element's 'frame' attribute in CVAT.\n",
    "    \"\"\"\n",
    "\n",
    "    # Manually seed known labels if you like,\n",
    "    # or leave empty and assign new IDs on the fly:\n",
    "    label_to_id = {\n",
    "        \"car\": 1,\n",
    "        \"bike\": 1,\n",
    "    }\n",
    "\n",
    "    frames_dict = defaultdict(list)\n",
    "\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Iterate over each \"track\" element in <annotations>\n",
    "    for track in root.findall(\"track\"):\n",
    "        label = track.attrib[\"label\"]  # e.g. \"car\" or \"bike\"\n",
    "        if label not in label_to_id:\n",
    "            # Assign a new ID if the label is not recognized\n",
    "            label_to_id[label] = len(label_to_id) + 1\n",
    "\n",
    "        track_id = track.attrib[\"id\"]  # track identifier as string\n",
    "\n",
    "        for box in track.findall(\"box\"):\n",
    "            frame_str = box.attrib[\"frame\"]\n",
    "            xtl = float(box.attrib[\"xtl\"])\n",
    "            ytl = float(box.attrib[\"ytl\"])\n",
    "            xbr = float(box.attrib[\"xbr\"])\n",
    "            ybr = float(box.attrib[\"ybr\"])\n",
    "            outside = box.attrib[\"outside\"]  # \"0\" or \"1\"\n",
    "\n",
    "            # Check whether this box is marked 'parked'\n",
    "            parked = False\n",
    "            for attr_node in box.findall(\"attribute\"):\n",
    "                if attr_node.attrib.get(\"name\") == \"parked\":\n",
    "                    if attr_node.text.strip().lower() == \"true\":\n",
    "                        parked = True\n",
    "                        break\n",
    "\n",
    "            # Skip 'outside' (invisible) objects\n",
    "            if outside == \"1\" or label=='bike':\n",
    "                continue\n",
    "\n",
    "            # Convert to [x, y, w, h]\n",
    "            x = xtl\n",
    "            y = ytl\n",
    "            w = xbr - xtl\n",
    "            h = ybr - ytl\n",
    "\n",
    "            frame_idx = int(frame_str)\n",
    "            cat_id = label_to_id[label]\n",
    "\n",
    "            annotation = {\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"category_id\": cat_id,\n",
    "                \"track_id\": track_id,\n",
    "                \"conf\": 1,\n",
    "            }\n",
    "\n",
    "            frames_dict[frame_idx].append(annotation)\n",
    "    return frames_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0aDfyLLgxtt"
   },
   "source": [
    "## TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jYIF9lkqboGE"
   },
   "outputs": [],
   "source": [
    "def parse_detection_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads the detection text file and returns data grouped by frame.\n",
    "    Each element in the returned list corresponds to a single frame,\n",
    "    which itself is a list of dictionaries.\n",
    "    Each dictionary has keys: 'bbox' -> [left, top, width, height], 'conf' -> conf_value\n",
    "\n",
    "    :param filepath: Path to the input text file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Using a dictionary to accumulate detections by frame number:\n",
    "    frames_dict = defaultdict(list)\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            # Strip and skip any empty lines\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Split line into fields\n",
    "            fields = line.split(',')\n",
    "            # fields are expected as: frame, -1, left, top, width, height, conf, -1, -1, -1\n",
    "\n",
    "            frame = int(fields[0].strip())-1\n",
    "            left  = float(fields[2].strip())\n",
    "            top   = float(fields[3].strip())\n",
    "            width = float(fields[4].strip())\n",
    "            height= float(fields[5].strip())\n",
    "            conf  = float(fields[6].strip())\n",
    "\n",
    "            # Construct detection dictionary\n",
    "            detection = {\n",
    "                'bbox': [left, top, width, height],\n",
    "                'conf': conf\n",
    "            }\n",
    "\n",
    "            # Append the detection to the corresponding frame\n",
    "            frames_dict[frame].append(detection)\n",
    "\n",
    "    return frames_dict\n",
    "\n",
    "\n",
    "def save_tracking_data(filepath, tracking_data):\n",
    "    \"\"\"\n",
    "    Saves tracking data to a file in the format:\n",
    "      frame,id,left,top,width,height,conf,-1,-1,-1\n",
    "\n",
    "    :param filepath: Path to the output text file.\n",
    "    :param tracking_data: A list of frames (list),\n",
    "                          where each frame is a list of dictionaries.\n",
    "                          Each dictionary has keys:\n",
    "                            {\n",
    "                                'id': <integer ID>,\n",
    "                                'bbox': [left, top, width, height],\n",
    "                                'conf': <float confidence>\n",
    "                            }\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        # 'frame_idx' will start from 1, but adjust if your frames are 0-based\n",
    "        for frame_idx, detections in enumerate(tracking_data, start=1):\n",
    "            for det in detections:\n",
    "                box_id = det['track_id']\n",
    "                left, top, width, height = det['bbox']\n",
    "                conf = det['conf']\n",
    "                # Write one line per detection\n",
    "                line = f\"{frame_idx},{box_id},{left:.2f},{top:.2f},{width:.2f},{height:.2f},{conf:.2f},-1,-1,-1\"\n",
    "                f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UkL6GzRxeeE"
   },
   "source": [
    "# **TRACKING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUDxCZStjswo"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JqxGnE2BxltM"
   },
   "outputs": [],
   "source": [
    "def iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    Computes the Intersection-over-Union (IoU) of two boxes.\n",
    "    Each box is in the format [x, y, w, h].\n",
    "    \"\"\"\n",
    "    # Convert [x, y, w, h] to (xmin, ymin, xmax, ymax)\n",
    "    ax1, ay1 = box_a[0], box_a[1]\n",
    "    ax2, ay2 = ax1 + box_a[2], ay1 + box_a[3]\n",
    "\n",
    "    bx1, by1 = box_b[0], box_b[1]\n",
    "    bx2, by2 = bx1 + box_b[2], by1 + box_b[3]\n",
    "\n",
    "    # Intersection rectangle\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    intersection_area = inter_w * inter_h\n",
    "\n",
    "    # Areas of each box\n",
    "    area_a = box_a[2] * box_a[3]  # w*h\n",
    "    area_b = box_b[2] * box_b[3]\n",
    "\n",
    "    union_area = area_a + area_b - intersection_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "def union_box(box_a, box_b):\n",
    "    \"\"\"\n",
    "    Returns the bounding-box union of the two boxes\n",
    "    (the minimal rectangle that encloses both).\n",
    "    Each box is in the format [x, y, w, h].\n",
    "    \"\"\"\n",
    "    ax1, ay1 = box_a[0], box_a[1]\n",
    "    ax2, ay2 = ax1 + box_a[2], ay1 + box_a[3]\n",
    "\n",
    "    bx1, by1 = box_b[0], box_b[1]\n",
    "    bx2, by2 = bx1 + box_b[2], by1 + box_b[3]\n",
    "\n",
    "    union_x1 = min(ax1, bx1)\n",
    "    union_y1 = min(ay1, by1)\n",
    "    union_x2 = max(ax2, bx2)\n",
    "    union_y2 = max(ay2, by2)\n",
    "\n",
    "    return [union_x1, union_y1, union_x2 - union_x1, union_y2 - union_y1]\n",
    "\n",
    "\n",
    "def union_of_boxes(list_of_boxes):\n",
    "    \"\"\"\n",
    "    Given a list of [x, y, w, h] boxes, returns the bounding box that encloses them all.\n",
    "    \"\"\"\n",
    "    if not list_of_boxes:\n",
    "        return None\n",
    "\n",
    "    # Initialize x1, y1 with a large value, x2, y2 with a small value\n",
    "    x1 = float('inf')\n",
    "    y1 = float('inf')\n",
    "    x2 = float('-inf')\n",
    "    y2 = float('-inf')\n",
    "\n",
    "    for (x, y, w, h) in list_of_boxes:\n",
    "        # Convert [x, y, w, h] into corners\n",
    "        bx1, by1 = x, y\n",
    "        bx2, by2 = x + w, y + h\n",
    "\n",
    "        # Update union coordinates\n",
    "        x1 = min(x1, bx1)\n",
    "        y1 = min(y1, by1)\n",
    "        x2 = max(x2, bx2)\n",
    "        y2 = max(y2, by2)\n",
    "\n",
    "    # Convert corners back to [x, y, w, h]\n",
    "    return [x1, y1, x2 - x1, y2 - y1]\n",
    "\n",
    "\n",
    "def merge_overlapping_boxes(bboxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Given a list of bounding boxes [ [x, y, w, h], ... ],\n",
    "    merges any two boxes whose IoU > iou_threshold into their union.\n",
    "    Repeats until no further merges are found.\n",
    "    Returns the merged list of boxes.\n",
    "    \"\"\"\n",
    "    merged = True\n",
    "    boxes = bboxes[:]\n",
    "\n",
    "    # Keep merging until no more merges happen\n",
    "    while merged:\n",
    "        merged = False\n",
    "        new_boxes = []\n",
    "        while boxes:\n",
    "            current_box = boxes.pop()\n",
    "            # Try to merge current_box with one of the boxes already in new_boxes\n",
    "            for i, nb in enumerate(new_boxes):\n",
    "                if iou(current_box['bbox'], nb['bbox']) > iou_threshold:\n",
    "                    # Merge them\n",
    "                    merged_box = union_box(current_box['bbox'], nb['bbox'])\n",
    "                    merged_conf = max(current_box['conf'], nb['conf'])\n",
    "                    # Replace the box in new_boxes with the merged box\n",
    "                    new_boxes[i] = {'bbox': merged_box, 'conf': merged_conf}\n",
    "                    merged = True\n",
    "                    break\n",
    "            else:\n",
    "                # If we never broke, it means no merge happened; keep current_box\n",
    "                new_boxes.append(current_box)\n",
    "        boxes = new_boxes\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def preprocess_detections_dict(detections_per_frame, iou_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Takes a dictionary where the keys are frame indices and the values are lists of bounding boxes.\n",
    "    Merges overlapping boxes in each frame if IoU > iou_threshold.\n",
    "    Returns a dictionary of the same structure with merged boxes.\n",
    "\n",
    "    Example:\n",
    "        detections_per_frame = {\n",
    "            0: [ [x0, y0, w0, h0], [x1, y1, w1, h1], ... ],\n",
    "            1: [ [x2, y2, w2, h2], ... ],\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    merged_frames = {}\n",
    "    for frame_idx, frame_bboxes in detections_per_frame.items():\n",
    "        merged_bboxes = merge_overlapping_boxes(frame_bboxes, iou_threshold)\n",
    "        merged_frames[frame_idx] = merged_bboxes\n",
    "    return merged_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rcSz-Ylj0YM"
   },
   "source": [
    "## Maximum Overlap Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FJqXJSq3Lrx3"
   },
   "outputs": [],
   "source": [
    "def tracking_postprocessing(tracking_by_frame, min_frames=3):\n",
    "    \"\"\"\n",
    "    - Merges all boxes in a single frame that share the same tracking_id\n",
    "      into one bounding box (their union).\n",
    "    - Removes any track IDs that do not appear in at least `min_frames` frames.\n",
    "\n",
    "    :param tracking_by_frame: dict of:\n",
    "        {\n",
    "            frame_idx: [\n",
    "                {\n",
    "                    \"bbox\": [x, y, w, h],\n",
    "                    \"track_id\": <int>,\n",
    "                    ... (other fields possible)\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            ...\n",
    "        }\n",
    "    :param min_frames: the minimum number of frames a track_id must appear in\n",
    "                       to remain in the final output.\n",
    "    :return: A new dictionary with the same structure, but merged and filtered.\n",
    "    \"\"\"\n",
    "    # 1. Count how many frames each track_id appears in\n",
    "    frames_for_track_id = defaultdict(set)  # track_id -> set of frame_idxs\n",
    "    for frame_idx, detections in tracking_by_frame.items():\n",
    "        for det in detections:\n",
    "            tid = det[\"track_id\"]\n",
    "            frames_for_track_id[tid].add(frame_idx)\n",
    "\n",
    "    # 2. Determine which track_ids appear in >= min_frames\n",
    "    valid_track_ids = set()\n",
    "    for tid, frames_set in frames_for_track_id.items():\n",
    "        if len(frames_set) >= min_frames:\n",
    "            valid_track_ids.add(tid)\n",
    "\n",
    "    # 3. Merge boxes for each track_id within a frame\n",
    "    new_tracking_by_frame = {}\n",
    "    for frame_idx, detections in tracking_by_frame.items():\n",
    "        # Group boxes by track_id\n",
    "        boxes_by_tid = defaultdict(list)\n",
    "        for det in detections:\n",
    "            tid = det[\"track_id\"]\n",
    "            # Only keep track if tid is valid\n",
    "            if tid in valid_track_ids:\n",
    "                boxes_by_tid[tid].append(det[\"bbox\"])\n",
    "\n",
    "        # Now merge boxes for each track_id in this frame\n",
    "        merged_detections = []\n",
    "        for tid, box_list in boxes_by_tid.items():\n",
    "            merged_box = union_of_boxes(box_list)\n",
    "            new_det = {\n",
    "                \"track_id\": tid,\n",
    "                \"bbox\": merged_box\n",
    "            }\n",
    "            merged_detections.append(new_det)\n",
    "\n",
    "        # Store back\n",
    "        new_tracking_by_frame[frame_idx] = merged_detections\n",
    "\n",
    "    return new_tracking_by_frame\n",
    "\n",
    "def track_by_maximum_overlap(detections_per_frame, iou_threshold=0.2, min_hits=3):\n",
    "    \"\"\"\n",
    "    Tracks objects from frame to frame by assigning track IDs according to maximum overlap (IoU).\n",
    "\n",
    "    :param detections_per_frame: Dictionary of {frame_idx: [ { \"bbox\": [...], ... }, ... ] }\n",
    "                                 Each box dict can have other fields like \"conf\" if you want.\n",
    "    :param iou_threshold: The minimum IoU needed to consider a box in the current frame\n",
    "                          as matching a box in the previous frame.\n",
    "    :return: Dictionary {frame_idx: [ { \"bbox\": [...], \"track_id\": <int>, ... }, ... ] },\n",
    "             same shape as input, but each detection has a track_id assigned.\n",
    "    \"\"\"\n",
    "    frame_indices = sorted(detections_per_frame.keys())\n",
    "\n",
    "    next_track_id = 1\n",
    "\n",
    "    tracking_by_frame = defaultdict(list)\n",
    "\n",
    "    for frame_idx in frame_indices:\n",
    "        current_detections = detections_per_frame[frame_idx]\n",
    "        previous_tracked = tracking_by_frame[frame_idx-1]\n",
    "        new_tracked_detections = []\n",
    "\n",
    "        for detection in current_detections:\n",
    "\n",
    "            best_iou = 0.0\n",
    "            best_track_id = None\n",
    "            for prev_detection in previous_tracked:\n",
    "                overlap = iou(detection['bbox'], prev_detection['bbox'])\n",
    "                if overlap > iou_threshold and overlap > best_iou:\n",
    "                    best_iou = overlap\n",
    "                    best_track_id = prev_detection['track_id']\n",
    "\n",
    "            if best_track_id is not None:\n",
    "                assigned_id = best_track_id\n",
    "            else:\n",
    "                assigned_id = next_track_id\n",
    "                next_track_id += 1\n",
    "\n",
    "            new_det = dict(detection)\n",
    "            new_det[\"track_id\"] = assigned_id\n",
    "            new_tracked_detections.append(new_det)\n",
    "\n",
    "        tracking_by_frame[frame_idx] = new_tracked_detections\n",
    "\n",
    "    return tracking_postprocessing(tracking_by_frame, min_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsA1zEzWkC0x"
   },
   "source": [
    "## SORT Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90YaPwi-iJVP"
   },
   "source": [
    "### SORT Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6RYcNY6xkITB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def linear_assignment(cost_matrix):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    x, y = linear_sum_assignment(cost_matrix)\n",
    "    return np.array(list(zip(x, y)))\n",
    "\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "    \"\"\"\n",
    "    From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "    \"\"\"\n",
    "    bb_gt = np.expand_dims(bb_gt, 0)\n",
    "    bb_test = np.expand_dims(bb_test, 1)\n",
    "\n",
    "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])\n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)\n",
    "    return(o)\n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "    \"\"\"\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    x = bbox[0] + w/2.\n",
    "    y = bbox[1] + h/2.\n",
    "    s = w * h    #scale is just area\n",
    "    r = w / float(h)\n",
    "    return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "    \"\"\"\n",
    "    w = np.sqrt(x[2] * x[3])\n",
    "    h = x[2] / w\n",
    "    if(score==None):\n",
    "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "    else:\n",
    "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "    \"\"\"\n",
    "    This class represents the internal state of individual tracked objects observed as bbox.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    def __init__(self,bbox):\n",
    "        \"\"\"\n",
    "        Initialises a tracker using initial bounding box.\n",
    "        \"\"\"\n",
    "        #define constant velocity model\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "        self.kf.R[2:,2:] *= 10.\n",
    "        self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1,-1] *= 0.01\n",
    "        self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "        self.history = []\n",
    "        self.hits = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "\n",
    "    def update(self,bbox):\n",
    "        \"\"\"\n",
    "        Updates the state vector with observed bbox.\n",
    "        \"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.hits += 1\n",
    "        self.hit_streak += 1\n",
    "        self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Advances the state vector and returns the predicted bounding box estimate.\n",
    "        \"\"\"\n",
    "        if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "            self.kf.x[6] *= 0.0\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        if(self.time_since_update>0):\n",
    "            self.hit_streak = 0\n",
    "        self.time_since_update += 1\n",
    "        self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "        return self.history[-1]\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Returns the current bounding box estimate.\n",
    "        \"\"\"\n",
    "        return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "\n",
    "def associate_detections_to_trackers(detections, trackers, iou_threshold = 0.3):\n",
    "    \"\"\"\n",
    "    Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "    Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "    \"\"\"\n",
    "    if(len(trackers)==0):\n",
    "        return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "    iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "    if min(iou_matrix.shape) > 0:\n",
    "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "        if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "            matched_indices = np.stack(np.where(a), axis=1)\n",
    "        else:\n",
    "            matched_indices = linear_assignment(-iou_matrix)\n",
    "    else:\n",
    "        matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "    unmatched_detections = []\n",
    "    for d, det in enumerate(detections):\n",
    "        if(d not in matched_indices[:,0]):\n",
    "            unmatched_detections.append(d)\n",
    "    unmatched_trackers = []\n",
    "    for t, trk in enumerate(trackers):\n",
    "        if(t not in matched_indices[:,1]):\n",
    "            unmatched_trackers.append(t)\n",
    "\n",
    "    #filter out matched with low IOU\n",
    "    matches = []\n",
    "    for m in matched_indices:\n",
    "        if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "            unmatched_detections.append(m[0])\n",
    "            unmatched_trackers.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1,2))\n",
    "    if(len(matches)==0):\n",
    "        matches = np.empty((0,2),dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class Sort(object):\n",
    "  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Sets key parameters for SORT\n",
    "    \"\"\"\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers = []\n",
    "    self.frame_count = 0\n",
    "\n",
    "  def update(self, dets=np.empty((0, 5))):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks = np.zeros((len(self.trackers), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "    for t in reversed(to_del):\n",
    "      self.trackers.pop(t)\n",
    "    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "\n",
    "    # update matched trackers with assigned detections\n",
    "    for m in matched:\n",
    "      self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "    # create and initialise new trackers for unmatched detections\n",
    "    for i in unmatched_dets:\n",
    "        trk = KalmanBoxTracker(dets[i,:])\n",
    "        self.trackers.append(trk)\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0]\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "      return np.concatenate(ret)\n",
    "    return np.empty((0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzdJJ2aAp7n4"
   },
   "source": [
    "### Tracking with SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LkLoLXT5p-zr"
   },
   "outputs": [],
   "source": [
    "def track_by_sort(detections_per_frame, iou_threshold=0.2, min_hits=3, max_age=1):\n",
    "    \"\"\"\n",
    "    Uses the SORT tracker to assign track IDs to detections from frame to frame.\n",
    "\n",
    "    :param detections_per_frame: Dictionary {frame_idx: [ { \"bbox\": [x1,y1,x2,y2], \"conf\": ... }, ... ]}\n",
    "    :param iou_threshold: IoU threshold for data association in SORT.\n",
    "    :param min_hits: Minimum number of hits before a track is output.\n",
    "    :param max_age: Maximum frames to keep alive a track without seeing it again.\n",
    "    :return: Dictionary {frame_idx: [ { \"bbox\": [...], \"track_id\": <int> }, ... ] }\n",
    "             Each detection is assigned a \"track_id\" from SORT.\n",
    "    \"\"\"\n",
    "    # 1) Create the SORT object with desired parameters\n",
    "    tracker = Sort(max_age=max_age, min_hits=min_hits, iou_threshold=iou_threshold)\n",
    "\n",
    "    # 2) Sort the frame indices so we process in order\n",
    "    frame_indices = sorted(detections_per_frame.keys())\n",
    "\n",
    "    # 3) Prepare the result dict\n",
    "    tracking_by_frame = defaultdict(list)\n",
    "\n",
    "    # 4) Main loop over frames\n",
    "    for frame_idx in frame_indices:\n",
    "        # Convert list of detection dicts -> Nx5 array: [x1, y1, x2, y2, score]\n",
    "        current_detections = detections_per_frame[frame_idx]\n",
    "        dets_array = []\n",
    "        for det in current_detections:\n",
    "            box = det[\"bbox\"]  # Must be [x1,y1,x2,y2]\n",
    "            score = det.get(\"conf\", 1.0)  # Default to 1.0 if not provided\n",
    "            dets_array.append([box[0], box[1], box[2]+box[0], box[3]+box[1], score])\n",
    "\n",
    "        # If no detections, an empty array\n",
    "        dets_array = np.array(dets_array) if len(dets_array) > 0 else np.empty((0, 5))\n",
    "\n",
    "        # 5) Pass the detections to the SORT tracker\n",
    "        tracked = tracker.update(dets_array)\n",
    "        # 'tracked' is an array of shape (N, 5) -> [x1, y1, x2, y2, track_id]\n",
    "\n",
    "        # 6) Build a list of detection dicts from the tracked results\n",
    "        frame_output = []\n",
    "        for t in tracked:\n",
    "            x1, y1, x2, y2, track_id = t\n",
    "            out_det = {\n",
    "                \"bbox\": [float(x1), float(y1), float(x2) - float(x1), float(y2)-float(y1)],\n",
    "                \"track_id\": int(track_id)\n",
    "            }\n",
    "            frame_output.append(out_det)\n",
    "\n",
    "        tracking_by_frame[frame_idx] = frame_output\n",
    "\n",
    "    return dict(tracking_by_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2xM6GHQxWYC"
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4sRVzIl-d_3E"
   },
   "outputs": [],
   "source": [
    "detections = parse_detection_file(\"../train/S03/c010/det/det_mask_rcnn.txt\")\n",
    "annotations = parse_cvat_annotations(\"../ai_challenge_s03_c010-full_annotation.xml\")\n",
    "\n",
    "detections_f = preprocess_detections_dict(detections)\n",
    "\n",
    "tracking_1 = track_by_maximum_overlap(detections_f)\n",
    "tracking_2 = track_by_sort(detections_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n76HOGLQmSPc"
   },
   "outputs": [],
   "source": [
    "video_player.plot(start_frame=861, end_frame=921, bounding_boxes_gt=annotations, bounding_boxes_pred=detections)\n",
    "video_player.plot(start_frame=861, end_frame=921, bounding_boxes_gt=annotations, bounding_boxes_pred=detections_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "NF5E3LVymj5H",
    "outputId": "f6508b97-aad9-44c8-ca34-9ba6123123c5"
   },
   "outputs": [],
   "source": [
    "video_player.plot(start_frame=0, end_frame=3, bounding_boxes_pred=tracking_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_player.plot(start_frame=0, end_frame=3, bounding_boxes_gt=annotations, bounding_boxes_pred=tracking_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "0tDGVFlrh1-t",
    "outputId": "2268febe-719a-41d3-fc34-55392cff50dd"
   },
   "outputs": [],
   "source": [
    "video_player.plot(start_frame=0, end_frame=3, bounding_boxes_pred=tracking_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Have to remove frame -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hk6c3n97iT7B",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_1.pop(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///mnt/home/mcv-c6-2025-team5/Week2/TrackEval\n",
      "doneuild dependencies ... \u001b[?25l\n",
      "doneGetting requirements to build wheel ... \u001b[?25l\n",
      "done  Preparing wheel metadata ... \u001b[?25l\n",
      "Requirement already satisfied: numpy in /mnt/home/.local/lib/python3.8/site-packages (from trackeval==1.0.dev1) (1.24.4)\n",
      "Requirement already satisfied: scipy in /mnt/home/.local/lib/python3.8/site-packages (from trackeval==1.0.dev1) (1.10.1)\n",
      "Installing collected packages: trackeval\n",
      "  Attempting uninstall: trackeval\n",
      "    Found existing installation: trackeval 1.0.dev1\n",
      "    Uninstalling trackeval-1.0.dev1:\n",
      "      Successfully uninstalled trackeval-1.0.dev1\n",
      "  Running setup.py develop for trackeval\n",
      "Successfully installed trackeval\n"
     ]
    }
   ],
   "source": [
    "!cd TrackEval/ && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackeval.metrics.hota import HOTA\n",
    "from trackeval.metrics.identity import Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(tracker_data, gt_data):\n",
    "    # build mapping dict for tracker\n",
    "    unique_tracker_ids_tr = set()\n",
    "    for frame, dets in tracker_data.items():\n",
    "        for det in dets:\n",
    "            unique_tracker_ids_tr.add(det['track_id'])\n",
    "    unique_tracker_ids_tr = sorted(list(unique_tracker_ids_tr))\n",
    "    tracker_id_mapping_tr = {old_id: new_id for new_id, old_id in enumerate(unique_tracker_ids_tr)}\n",
    "    \n",
    "    # build mapping dict for gt\n",
    "    unique_tracker_ids_gt = set()\n",
    "    for frame, dets in gt_data.items():\n",
    "        for det in dets:\n",
    "            unique_tracker_ids_gt.add(det['track_id'])\n",
    "    unique_tracker_ids_gt = sorted(list(unique_tracker_ids_gt))\n",
    "    tracker_id_mapping_gt = {old_id: new_id for new_id, old_id in enumerate(unique_tracker_ids_gt)}\n",
    "    \n",
    "    all_frames = sorted(set(gt_data.keys()).union(tracker_data.keys()))\n",
    "    \n",
    "    gt_ids_list = []\n",
    "    tracker_ids_list = []\n",
    "    similarity_scores_list = []\n",
    "    total_tracker_dets = 0\n",
    "    total_gt_dets = 0\n",
    "    \n",
    "    for frame in all_frames:\n",
    "        gt_dets = gt_data[frame]\n",
    "        tr_dets = tracker_data[frame]\n",
    "        \n",
    "        total_gt_dets += len(gt_dets)\n",
    "        total_tracker_dets += len(tr_dets)\n",
    "        \n",
    "        # remap track IDs for gt\n",
    "        gt_ids = np.array([tracker_id_mapping_gt[det['track_id']] for det in gt_dets])\n",
    "        # remap track IDs for tr\n",
    "        tr_ids = np.array([tracker_id_mapping_tr[det['track_id']] for det in tr_dets])\n",
    "        \n",
    "        if len(gt_dets) > 0 and len(tr_dets) > 0:\n",
    "            sim_matrix = np.zeros((len(gt_dets), len(tr_dets)), dtype=float)\n",
    "            for i, gt in enumerate(gt_dets):\n",
    "                for j, tr in enumerate(tr_dets):\n",
    "                    sim_matrix[i, j] = iou(gt['bbox'], tr['bbox'])\n",
    "        else:\n",
    "            sim_matrix = np.zeros((len(gt_dets), len(tr_dets)), dtype=float)\n",
    "        \n",
    "        gt_ids_list.append(gt_ids)\n",
    "        # gt_ids_list.append(np.array([int(a['track_id']) for a in gt_dets]))\n",
    "        tracker_ids_list.append(tr_ids)\n",
    "        # tracker_ids_list.append(np.array([int(a['track_id']) for a in tr_dets]))\n",
    "        similarity_scores_list.append(sim_matrix)\n",
    "    \n",
    "    \n",
    "    num_gt_ids = len(unique_tracker_ids_gt)\n",
    "    num_tracker_ids = len(unique_tracker_ids_tr)\n",
    "    \n",
    "    # data dictionary for HOTA\n",
    "    data = {\n",
    "        'num_tracker_dets': total_tracker_dets,\n",
    "        'num_gt_dets': total_gt_dets,\n",
    "        'num_gt_ids': num_gt_ids,\n",
    "        'num_tracker_ids': num_tracker_ids,\n",
    "        'gt_ids': gt_ids_list,\n",
    "        'tracker_ids': tracker_ids_list,\n",
    "        'similarity_scores': similarity_scores_list\n",
    "    }\n",
    "    \n",
    "    hota_metric = HOTA()\n",
    "    identity_metric = Identity()\n",
    "    result_hota = hota_metric.eval_sequence(data)\n",
    "    result_identity = identity_metric.eval_sequence(data)\n",
    "    return result_hota, result_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identity Config:\n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'HOTA': array([0.66116379, 0.66064385, 0.65922814, 0.65668806, 0.65401819,\n",
       "         0.65045638, 0.62927106, 0.54019389, 0.52443087, 0.51698678,\n",
       "         0.51149629, 0.50422555, 0.49195857, 0.48366427, 0.47339261,\n",
       "         0.45232037, 0.4028273 , 0.30987649, 0.0406153 ]),\n",
       "  'DetA': array([0.5631787 , 0.56218499, 0.55935276, 0.55449123, 0.54896223,\n",
       "         0.54160505, 0.5171988 , 0.40470358, 0.36345262, 0.34785504,\n",
       "         0.33966746, 0.32639371, 0.29494128, 0.27786651, 0.2655043 ,\n",
       "         0.24751614, 0.21273221, 0.14718239, 0.01394005]),\n",
       "  'AssA': array([0.77619689, 0.77634641, 0.7769368 , 0.77772052, 0.77917891,\n",
       "         0.78118456, 0.76562836, 0.72104487, 0.75670863, 0.7683526 ,\n",
       "         0.7702488 , 0.77894703, 0.82058108, 0.84188312, 0.84405622,\n",
       "         0.82658739, 0.76278922, 0.6524112 , 0.11833547]),\n",
       "  'DetRe': array([0.5752541 , 0.57460435, 0.57274795, 0.56954564, 0.56587924,\n",
       "         0.56095976, 0.54429851, 0.46001764, 0.4256277 , 0.41207593,\n",
       "         0.40483594, 0.39290853, 0.36367012, 0.34719451, 0.33498863,\n",
       "         0.31679584, 0.28008539, 0.2048545 , 0.02195201]),\n",
       "  'DetPr': array([0.96406627, 0.96297737, 0.95986622, 0.95449949, 0.94835498,\n",
       "         0.94011045, 0.91218791, 0.7709419 , 0.71330793, 0.69059656,\n",
       "         0.67846309, 0.65847398, 0.60947344, 0.58186202, 0.56140624,\n",
       "         0.53091701, 0.4693941 , 0.34331493, 0.0367893 ]),\n",
       "  'AssRe': array([0.78462117, 0.78486274, 0.78519733, 0.78564341, 0.78551811,\n",
       "         0.7856751 , 0.77944041, 0.73446507, 0.76578676, 0.77976089,\n",
       "         0.78357367, 0.79439837, 0.83912892, 0.8633164 , 0.87064061,\n",
       "         0.86683485, 0.82632183, 0.72860224, 0.1833976 ]),\n",
       "  'AssPr': array([0.9764386 , 0.97625841, 0.97557807, 0.97369639, 0.97290751,\n",
       "         0.97195636, 0.95078024, 0.89596453, 0.91747089, 0.92193815,\n",
       "         0.91754507, 0.90839349, 0.91134898, 0.92165052, 0.92022051,\n",
       "         0.90759994, 0.85501762, 0.7422895 , 0.1937366 ]),\n",
       "  'LocA': array([0.71468451, 0.71540551, 0.7173094 , 0.72036289, 0.72355336,\n",
       "         0.72747719, 0.73961964, 0.80595179, 0.83718698, 0.84930179,\n",
       "         0.85508504, 0.86344871, 0.88246197, 0.89258596, 0.89864427,\n",
       "         0.90557622, 0.91569222, 0.9292763 , 0.96010854]),\n",
       "  'OWTA': array([0.66821437, 0.66790121, 0.66707492, 0.66554289, 0.66401895,\n",
       "         0.66197667, 0.64554657, 0.57592826, 0.56751754, 0.56268962,\n",
       "         0.55841239, 0.55322231, 0.54627906, 0.54064516, 0.5317417 ,\n",
       "         0.51172204, 0.46221869, 0.36558087, 0.05096765]),\n",
       "  'HOTA_TP': array([12395., 12381., 12341., 12272., 12193., 12087., 11728.,  9912.,\n",
       "          9171.,  8879.,  8723.,  8466.,  7836.,  7481.,  7218.,  6826.,\n",
       "          6035.,  4414.,   473.]),\n",
       "  'HOTA_FN': array([ 9152.,  9166.,  9206.,  9275.,  9354.,  9460.,  9819., 11635.,\n",
       "         12376., 12668., 12824., 13081., 13711., 14066., 14329., 14721.,\n",
       "         15512., 17133., 21074.]),\n",
       "  'HOTA_FP': array([  462.,   476.,   516.,   585.,   664.,   770.,  1129.,  2945.,\n",
       "          3686.,  3978.,  4134.,  4391.,  5021.,  5376.,  5639.,  6031.,\n",
       "          6822.,  8443., 12384.]),\n",
       "  'HOTA(0)': np.float64(0.6611637895641874),\n",
       "  'LocA(0)': np.float64(0.7146845109043398),\n",
       "  'HOTALocA(0)': np.float64(0.4725235195723411)},\n",
       " {'IDF1': np.float64(0.45204046041158),\n",
       "  'IDR': np.float64(0.36088550610293774),\n",
       "  'IDP': np.float64(0.6048067200746675),\n",
       "  'IDTP': np.int64(7776),\n",
       "  'IDFN': np.int64(13771),\n",
       "  'IDFP': np.int64(5081)})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = calculate_metrics(tracking_1, dict(annotations))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identity Config:\n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'HOTA': array([0.52786818, 0.52724032, 0.52643001, 0.52514403, 0.52352546,\n",
       "         0.52126253, 0.50693996, 0.42940318, 0.41445576, 0.40563123,\n",
       "         0.3995102 , 0.390666  , 0.38022795, 0.37068593, 0.35561858,\n",
       "         0.3301802 , 0.29609274, 0.26471752, 0.02968189]),\n",
       "  'DetA': array([0.63658788, 0.63299919, 0.6284809 , 0.62167807, 0.61222055,\n",
       "         0.60294311, 0.57908174, 0.45151154, 0.3878071 , 0.35719865,\n",
       "         0.34128501, 0.32276072, 0.29437429, 0.27475023, 0.2545467 ,\n",
       "         0.21970051, 0.17112231, 0.11709423, 0.00962842]),\n",
       "  'AssA': array([0.43771618, 0.4391512 , 0.44094985, 0.44359977, 0.44768002,\n",
       "         0.4506472 , 0.44378558, 0.40837737, 0.4429356 , 0.46063078,\n",
       "         0.46766895, 0.4728578 , 0.49112066, 0.5001199 , 0.49682267,\n",
       "         0.49621625, 0.51232895, 0.5984528 , 0.09150147]),\n",
       "  'DetRe': array([0.658746  , 0.6564719 , 0.65359447, 0.64923191, 0.64310577,\n",
       "         0.63702604, 0.62106094, 0.52680187, 0.47324454, 0.4457233 ,\n",
       "         0.43091846, 0.41323618, 0.38515803, 0.36501601, 0.34362092,\n",
       "         0.30505407, 0.24745904, 0.17751891, 0.01615074]),\n",
       "  'DetPr': array([0.94981263, 0.94653373, 0.9423849 , 0.93609475, 0.92726178,\n",
       "         0.91849572, 0.89547645, 0.75956906, 0.68234743, 0.64266595,\n",
       "         0.62131959, 0.59582441, 0.55533994, 0.52629818, 0.49544968,\n",
       "         0.43984208, 0.35679872, 0.25595557, 0.02328694]),\n",
       "  'AssRe': array([0.43797554, 0.43940069, 0.4412087 , 0.44390046, 0.44796821,\n",
       "         0.45117144, 0.4489818 , 0.41186734, 0.44503958, 0.46486311,\n",
       "         0.47330223, 0.48060296, 0.5009347 , 0.51239409, 0.51394498,\n",
       "         0.51921965, 0.53246579, 0.61453054, 0.14186662]),\n",
       "  'AssPr': array([0.9415469 , 0.94221507, 0.94245013, 0.94254014, 0.94348249,\n",
       "         0.94341108, 0.93273783, 0.89561976, 0.91412412, 0.93162085,\n",
       "         0.93123103, 0.9155277 , 0.89936589, 0.89616233, 0.88204029,\n",
       "         0.86051083, 0.83241616, 0.79800298, 0.20763373]),\n",
       "  'LocA': array([0.68223332, 0.68432697, 0.68678907, 0.690216  , 0.69465199,\n",
       "         0.69864458, 0.70808965, 0.76738915, 0.8063557 , 0.82704115,\n",
       "         0.83740721, 0.84842871, 0.86463586, 0.87523943, 0.88448088,\n",
       "         0.89812197, 0.91485057, 0.92967627, 0.96101225]),\n",
       "  'OWTA': array([0.53697652, 0.53692683, 0.53684484, 0.5366555 , 0.53656836,\n",
       "         0.53579287, 0.52499323, 0.46382536, 0.45783933, 0.45311574,\n",
       "         0.44891779, 0.44204293, 0.43492421, 0.42726078, 0.41318115,\n",
       "         0.38906656, 0.3560624 , 0.3259397 , 0.03844238]),\n",
       "  'HOTA_TP': array([14194., 14145., 14083., 13989., 13857., 13726., 13382., 11351.,\n",
       "         10197.,  9604.,  9285.,  8904.,  8299.,  7865.,  7404.,  6573.,\n",
       "          5332.,  3825.,   348.]),\n",
       "  'HOTA_FN': array([ 7353.,  7402.,  7464.,  7558.,  7690.,  7821.,  8165., 10196.,\n",
       "         11350., 11943., 12262., 12643., 13248., 13682., 14143., 14974.,\n",
       "         16215., 17722., 21199.]),\n",
       "  'HOTA_FP': array([  750.,   799.,   861.,   955.,  1087.,  1218.,  1562.,  3593.,\n",
       "          4747.,  5340.,  5659.,  6040.,  6645.,  7079.,  7540.,  8371.,\n",
       "          9612., 11119., 14596.]),\n",
       "  'HOTA(0)': np.float64(0.5278681819164659),\n",
       "  'LocA(0)': np.float64(0.6822333249361989),\n",
       "  'HOTALocA(0)': np.float64(0.36012926487689684)},\n",
       " {'IDF1': np.float64(0.30703461127401277),\n",
       "  'IDR': np.float64(0.25998978976191583),\n",
       "  'IDP': np.float64(0.37486616702355463),\n",
       "  'IDTP': np.int64(5602),\n",
       "  'IDFN': np.int64(15945),\n",
       "  'IDFP': np.int64(9342)})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = calculate_metrics(tracking_2, dict(annotations))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Twq7M9Eaew5I",
    "64V6eKeHbm1M",
    "blQ_cWRxgmt0",
    "d0aDfyLLgxtt",
    "lUDxCZStjswo"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
